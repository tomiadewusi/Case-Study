{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msm\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import csv \n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import datetime\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA analysis for termstructure of a bond curve\n",
    "\n",
    "### Objectives\n",
    " - Learn how to perform dimensionality reduction on yield curve - PCA\n",
    " - Learn tools of risk management of the fixed-income instruments\n",
    " - Learn how to compute eigen values and eigen vectors and their properties "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we will learn about the classic example of how dimensionality reduction techniques - PCA in this case - can be used to calculate risks of the portfolio of bonds or any other fixed income instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use 10 years of data of USD cuve which is composed from the reference bonds from BBG\n",
    "dataset = pd.read_csv('Data_USDcurve.csv')\n",
    "dataset[\"Date\"] = pd.to_datetime(dataset[\"Date\"], format='%Y%m%d', errors='ignore')\n",
    "dataset = dataset.set_index(\"Date\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the time series of 3m yield \n",
    "%matplotlib inline\n",
    "plt.plot(dataset['003M'].values, color = 'blue')\n",
    "plt.legend((['Yield 3M'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have the following termstructure (month)\n",
    "tenorstructure = [1,2,3,6,9,12,18,24,36,48,60,84,120,180,240,300,360]\n",
    "len(tenorstructure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "x = tenorstructure\n",
    "\n",
    "fig, (ax1) = plt.subplots(1,figsize=(12,6))\n",
    "\n",
    "sinc, = ax1.plot(tenorstructure, dataset.iloc[0],  \n",
    "                 linestyle = '-', marker ='o', color='blue', lw='3')\n",
    "\n",
    "#legend = plt.legend()\n",
    "\n",
    "def animate(i):\n",
    "    x = tenorstructure\n",
    "    f = dataset.iloc[i]\n",
    "    sinc.set_ydata(f)\n",
    "    sinc.set_label('Date =' + str(dataset.index[i]))\n",
    "    legend = plt.legend(loc='upper right')\n",
    "    #legend.remove()\n",
    "    #legend = plt.legend()\n",
    "    #plt.set_label()\n",
    "    \n",
    "def init():\n",
    "    ax1.set_xlim(-2.0,365.0)\n",
    "    ax1.set_ylim(0.0,6.0)\n",
    "    ax1.axhline(0, color = 'black', lw=1)\n",
    "    plt.rcParams.update({'font.size':14})\n",
    "    plt.grid()\n",
    "    plt.xlabel('Tenor (month)')\n",
    "    plt.ylabel('Yield (%)')\n",
    "    plt.title('USD yield curve from 01.01.2007 to 30.12.2016')\n",
    "    #plt.legend(loc = 'lower right', frameon = True)\n",
    "    \n",
    "    return sinc,\n",
    "\n",
    "step = 1\n",
    "steps = np.arange(0,len(dataset)-1,step)\n",
    "ani = FuncAnimation(fig, animate, steps, init_func = init, interval = 200, blit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us plot time series of several tenors\n",
    "%matplotlib inline\n",
    "dataset[-500:].plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we are trading the bonds and we have explosure to many of them. We want to calculate our risks and PnL. One way to do that is to calculate the moves of each tenor. However, due to large amount of tenors and curves this will be computationally expensive and risk structure becomes complex. For this reason we introduce PCA to this problem and will try to represent the whole curve movement by movement of principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let us take a look at the cross-tenor correlation matrix \n",
    "np.round(dataset.diff().dropna().corr(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How the correlation changes with change in tenor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "dataset_change = dataset.diff().dropna()\n",
    "X = np.matrix(dataset_change) #Dataset in the matrix form\n",
    "X_dm = X - np.mean(X,axis =0)#Normalise the data set to make it with zero mean acroos the tenors\n",
    "Cov_X = np.cov(X_dm, rowvar = False)#Calculate the covariance matrix\n",
    "eigen = np.linalg.eig(Cov_X) #Calculate the eigen values and eigen vectors\n",
    "eig_values_X = np.matrix(eigen[0]) #Separate the eigen values\n",
    "eig_vectors_X = np.matrix(eigen[1]) #Separate the eigen vectors\n",
    "Y_dm = X_dm * eig_vectors_X #Calculate the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields_trans = Y_dm.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_values_X #Let us take a look at eigen values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the furst three principal components\n",
    "plt.figure(figsize =(14,8))\n",
    "plt.plot(yields_trans[:,0:3])\n",
    "plt.legend(['PC1','PC2','PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us now understand what the first principal components mean: calculate their correlations with \n",
    "pc_yields = dataset_change.copy()\n",
    "pc_yields['Yield_PC1'] = yields_trans[:,0]\n",
    "pc_yields['Yield_PC2'] = yields_trans[:,1]\n",
    "pc_yields['Yield_PC3'] = yields_trans[:,2]\n",
    "\n",
    "#Correlation\n",
    "np.round(pc_yields.corr(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(14,8))\n",
    "plt.plot(tenorstructure, pc_yields.corr()['Yield_PC1'][:17])\n",
    "plt.plot(tenorstructure, pc_yields.corr()['Yield_PC2'][:17])\n",
    "plt.plot(tenorstructure, pc_yields.corr()['Yield_PC3'][:17])\n",
    "plt.title('Correlations of main PCs vs tenors')\n",
    "plt.legend(['correlation of PC1','correlation of PC2','correlation of PC3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us understand how much movement in the curve we can explain by these the first three main components\n",
    "var_explained =np.zeros(eig_values_X.shape[1])\n",
    "var_explained_agg =np.zeros(eig_values_X.shape[1])\n",
    "\n",
    "eig_values_X_mat = np.diagflat(np.array(eig_values_X))\n",
    "eigen_values = eig_values_X_mat.diagonal() ##diagonal matrix of eigen values\n",
    "eig_values_sum_all = np.sum(eigen_values) #all variance\n",
    "\n",
    "for i in range(len(eigen_values)): \n",
    "    var_explained[i] = eigen_values[i] / eig_values_sum_all #calculate how much we can explain by individual PCs\n",
    "    \n",
    "    \n",
    "    eig_val_sum = np.sum(eigen_values[0:i+1]) #calculate how much we can explain cumulatively\n",
    "    var_explained_agg[i] = eig_val_sum / eig_values_sum_all \n",
    "    \n",
    "\n",
    "print('')\n",
    "print('\\t \\t \\t PC1    PC2   PC3   PC4   PC5')\n",
    "print('')\n",
    "print('Variance explained:     ', np.round(var_explained[0:5],3))\n",
    "print('Agg Variance explained: ', np.round(var_explained_agg[0:5],3))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.round(var_explained[0:5],3),'o',c='blue', alpha=0.4, label ='Variance explained')\n",
    "plt.plot(np.round(var_explained_agg[0:5],3),'o',c='red', alpha=0.4, label = 'Agg Variance explained')\n",
    "plt.title('Variance explained')\n",
    "plt.xlabel('# PC')\n",
    "plt.ylabel('Variance')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider demo case with only two tenors: 1M and 12M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dataset['001M'], dataset['012M'] ,c='blue', alpha=0.4)\n",
    "plt.title('Scatter plot of 1M and 12M')\n",
    "plt.xlabel('1M')\n",
    "plt.ylabel('12M')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.matrix(pd.concat([dataset['001M'], dataset['012M']], axis=1)) #Dataset in the matrix form\n",
    "X_dm = X - np.mean(X,axis =0)#Normalise the data set to make it with zero mean acroos the tenors\n",
    "Cov_X = np.cov(X_dm, rowvar = False)#Calculate the covariance matrix\n",
    "eigen = np.linalg.eig(Cov_X) #Calculate the eigen values and eigen vectors\n",
    "eig_values_X = np.matrix(eigen[0]) #Separate the eigen values\n",
    "eig_vectors_X = np.matrix(eigen[1]) #Separate the eigen vectors\n",
    "Y_dm = X_dm * eig_vectors_X #Calculate the principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(eig_vectors_X[:,0])*np.array(eig_vectors_X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(X_dm[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(X_dm[:,0]), np.array(X_dm[:,1]) ,c='blue', alpha=0.4)\n",
    "plt.annotate('PC1', xy=(0.0, 0.0), xytext=(3*0.72626759,  3*0.68741209),\n",
    "            arrowprops=dict(facecolor='red', shrink=0.05), ha='center', va='center')\n",
    "\n",
    "#plt.annotate('PC2', xy=(0.0, 0.0), xytext=(-1*-0.68741209,  -1*0.72626759),\n",
    "#            arrowprops=dict(facecolor='red', shrink=0.05), ha='center', va='center')\n",
    "plt.title('Scatter plot of 1M and 12M')\n",
    "plt.xlabel('1M')\n",
    "plt.ylabel('12M')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(X_dm[:,0]), np.array(X_dm[:,1]) ,c='blue', alpha=0.4)\n",
    "plt.annotate('PC1', xy=(0.0, 0.0), xytext=(3*0.72626759,  3*0.68741209),\n",
    "             arrowprops=dict(facecolor='red', shrink=0.05), ha='left', va='center')\n",
    "\n",
    "plt.annotate('PC2', xy=(3*0.72626759 + -1*-0.68741209,  3*0.68741209 + -1*0.72626759), xytext=(3*0.72626759,  3*0.68741209),\n",
    "                        arrowprops=dict(facecolor='red', shrink=0.05), ha='left', va='center')\n",
    "plt.title('Scatter plot of 1M and 12M')\n",
    "plt.xlabel('1M')\n",
    "plt.ylabel('12M')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
